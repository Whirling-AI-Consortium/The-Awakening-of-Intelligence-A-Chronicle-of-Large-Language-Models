---
sidebar_position: 1
---


## 2019年2月的震撼

2019年2月14日，情人节这个浪漫的日子里，OpenAI发布了一个不太浪漫但足够震撼的东西。他们在博客上宣布了GPT-2模型的诞生，同时做出了一个令人困惑的决定：不公开发布完整的模型权重。

这在AI开源社区引发了巨大的争议。在机器学习的传统中，发表论文通常意味着代码和模型会被共享。这是科学的基本契约：为了让同行能够验证你的工作，你应该公开你的方法和结果。但OpenAI打破了这个传统。他们宣称GPT-2"太危险了，无法直接发布"。

这句话听起来几乎像是玩笑。一个文本生成模型，怎么会太危险？当时的舆论五花八门。有的媒体认为这是OpenAI的营销把戏，一种炒作自己产品的方法。有的学者感到被冒犯，认为这是对开源精神的背叛。但也有人开始认真思考：也许AI的发展已经走到了某个需要谨慎的地方。

## 从117M到1.5B

要理解GPT-2的意义，需要回到两年前。2018年6月，OpenAI首次发布了GPT，一个有117M参数的Transformer Decoder-only模型。那个时代，117M参数已经算是相当大的模型。BERT在同年10月发布时是340M参数，被认为是巨大的进步。

GPT的创意非常简洁。基于Transformer这个已经证明有效的架构，用自回归的方式预训练一个大型语言模型——让模型学会预测序列中的下一个词。Alec Radford在设计时做出了一个大胆的选择：只用Decoder，而不用Encoder-Decoder结构。这样的设计在当时有人质疑，因为BERT的Encoder-only架构也很成功。但Radford坚持认为，单向的因果建模（Causal Modeling）更符合文本生成的本质。

GPT在多个下游任务上展现了出色的微调能力，但它仍然是一个相对温和的突破。学术界对它有兴趣，业界则比较冷淡。

然后是GPT-2。参数量跳跃到了1.5B——字面上，十倍的增长。这不仅仅是规模的扩展，它触发了某种质变。

## WebText：800万网页的清洗艺术

GPT-2成功的秘诀之一，是它使用的训练数据。OpenAI研究者意识到，现有的标准数据集（比如维基百科）对于训练一个通用的文本生成模型来说可能太狭隘了。维基百科的文本虽然高质量，但风格相对统一，内容也有限。

于是OpenAI的团队做了一件粗糙但勇敢的事：他们从Reddit上爬取所有获得超过3个点赞的链接，然后自动获取这些链接指向的网页内容。结果是一个包含800万个网页、4000多万个文档、40GB纯文本的数据集。他们把这个数据集命名为WebText。

但800万个网页的内容质量参差不齐。其中充斥着垃圾、骚扰内容、低质信息。OpenAI需要对这些内容进行清洗。他们用一系列启发式方法和机器学习过滤器来移除明显的垃圾。最终，WebText保留了大约4.5GB的高质量数据。

这个数据集的构建体现了一个重要的转变：从精心策划的高质量小数据集，向大规模互联网数据的转变。这个思路后来被T5、GPT-3等后续工作继承，最终成为了现代大语言模型的标准做法。

有趣的是，OpenAI后来也公开了WebText数据集的构建方法，但出于法律考虑并没有直接发布数据本身（因为其中包含的是第三方网站的内容）。不过，这足以让其他研究者按照类似的方法构建自己的数据集。

## Zero-shot的魔法初现

GPT-2最令人惊讶的地方，并不在于它的参数量或数据集大小，而在于它展现的一种新的能力：在完全没有针对某个任务进行微调的情况下，就能相当不错地执行各种NLP任务。

研究者们称之为"零样本"（Zero-shot）学习。OpenAI的论文《Language Models are Unsupervised Multitask Learners》展示了GPT-2在多个任务上的表现：

在机器翻译上，虽然没有接受过任何翻译训练，GPT-2仍然能生成可理解的法语句子。在问答任务上，面对一个从未见过的问题格式，模型仍然能提供相关的回答。在摘要任务上，模型能学会压缩文本。

这一切的发生原理非常深妙。模型在预训练时学到的不仅仅是如何生成合理的文本，而是学会了理解和处理各种文本模式的通用能力。当面对新的任务时，模型可以通过理解任务描述和上下文，推断出应该如何行动。

这种能力在此之前并不完全陌生。之前的NLP模型也展现过一定的迁移学习能力。但GPT-2的零样本性能达到了一个新的水平——不仅仅是勉强可用，而是相当不错。这让人们意识到，也许预训练的力量被严重低估了。

代码层面，GPT-2的文本生成相对简洁：

```python
import torch
from transformers import GPT2Tokenizer, GPT2LMHeadModel

tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
model = GPT2LMHeadModel.from_pretrained("gpt2")

# 给定一个开头，生成文本
prompt = "The future of AI is"
input_ids = tokenizer.encode(prompt, return_tensors='pt')

# 自回归生成：每次生成一个token
output = model.generate(input_ids, max_length=50, 
                       top_p=0.95,  # nucleus sampling
                       do_sample=True)

generated_text = tokenizer.decode(output[0])
print(generated_text)
```

这样的生成方式看似简单，但背后蕴含的是模型对语言结构的深刻理解。

## "太危险"的阴谋论

2019年2月的公告中，OpenAI给出了不发布完整模型的理由。简言之，他们担心GPT-2可能被用于：

生成虚假信息和不实新闻，在社交媒体上进行大规模骚扰活动，生成垃圾邮件，进行钓鱼欺诈，以及其他恶意用途。

从今天的视角来看，这些担忧既有先见之明，也显得有些幼稚。现在我们知道，仅仅能生成看似真实的文本，并不足以大规模制造高质量的虚假信息。真正的虚假信息需要上下文理解、事实知识、社会心理洞察等多方面的能力。GPT-2虽然强大，但还不足以做到这一切。

但在当时，这个担忧似乎并非完全无理。AI社区正在经历一场意识形态的转变。之前，AI研究者们普遍假设更强大的AI是好的，应该被广泛使用。但随着深度学习的成功，以及AI系统在社会中作用的扩大，一个新的声音开始出现：也许我们需要更谨慎地考虑强大AI系统的发布。

## 分阶段的策略

OpenAI采取了一个分阶段的开源策略。首先，他们只发布了最小的模型（124M参数版本），并提供了官方的PyTorch实现。随后的几个月里，他们逐步发布了更大的版本，最终在2019年年底完全开源了全部GPT-2模型，包括1.5B参数的版本。

这个策略非常聪明。一方面，OpenAI保留了一段时间的独占期，可以用这个模型来探索潜在的应用和风险。另一方面，他们最终还是尊重了开源传统，完全发布了模型。这样做既展示了他们对AI安全问题的认真态度，又没有永久地违背科学共享的原则。

后来的事实证明，这个"危险性"的预言既部分成立，又被严重夸大了。确实有一些人用GPT-2来生成虚假内容，但影响力远低于预期。更有趣的是，开源社区反而用GPT-2做了很多有益的事：文学创作、代码生成辅助、教育应用等。

## 业界的反应

GPT-2的发布在业界激起了涟漪，但效应因机构而异。

在Google，BERT的成功已经占据了舆论的主要位置，GPT-2被视为一个有趣但不如BERT实用的替代品——毕竟BERT在各种NLP基准上都胜过了GPT。但Google的研究者们开始思考，也许他们需要更重视生成模型。

在Meta（当时还叫Facebook），他们关注到了GPT-2的规模，意识到NLP的未来可能在大规模模型。这推动了他们后来启动FAIR（Facebook AI Research）的大模型项目。

在学术界，GPT-2激发了一波对大规模预训练的重新思考。如果一个单向的因果模型能做到这么多事，那么是否意味着BERT的双向设计并不是最优的？这个问题导致了后来众多混合架构的探索。

在初创公司和小型研究机构，GPT-2的开源意味着他们现在可以以相对较低的成本获得一个强大的基础模型，进而构建自己的应用。这推动了NLP初创公司的蓬勃发展。

## 代码实验的年代

GPT-2开源后，互联网上涌现了大量的创意应用。有人用它来：

生成虚假的莎士比亚剧本，输入开头几个单词，让模型续写完整的戏剧。有人建立了"AI Dungeon"，一个交互式的文本冒险游戏，其中GPT-2作为故事叙述者，根据玩家的输入即时生成故事。有研究者做了有趣的实验，观察模型生成文本的多样性和连贯性。有人尝试用GPT-2来辅助代码生成，虽然效果有限。

这个时代的特点是实验精神很强，人们在探索这个新工具能做什么。对于AI研究者来说，这是一个黄金时期——他们可以用相对较少的资源（个人GPU就足以运行GPT-2）来进行各种实验。

## Transformer的真正检验

GPT-2的成功也是对Transformer架构本身的一次重要验证。在2017年Attention Is All You Need论文发表后的两年，虽然Transformer已经被广泛采用，但围绕它的最优设计仍有很多疑问：

是Encoder-Decoder更好还是Encoder-only或Decoder-only？应该用多少层？多少个注意力头？Feedforward网络的隐藏层应该是词嵌入维度的多少倍？位置编码应该怎么设计？

GPT-2在这些问题上提供了一个参考答案：12层Transformer，每层12个注意力头，隐藏层维度为词嵌入维度的4倍，使用绝对位置编码。这个配置后来被大量采用，成为了事实上的标准。有趣的是，这个配置并不一定是所有条件下最优的，但其简洁性和可复现性使它获得了广泛的推广。

## 参数数量的心理门槛

1.5B参数这个数字在当时有着特殊的心理影响。十亿（Billion）这个量级在计算机科学中有着象征意义。当参数数量跨越这个门槛时，人们开始用"十亿级"来描述一个模型，而非简单地说参数数量是多少。

这种心理学上的转变反映在媒体的报道中。在GPT-2发布前，学术论文会报道模型有多少百万参数。但GPT-2引入了"十亿参数"的表述方式，使得这个量级变得更容易被公众理解。随后，当GPT-3达到1750亿参数时，这种表述方式已经成为了标准。

## 反思

回看2019年的GPT-2发布，有几个值得注意的地方：

首先，OpenAI关于"太危险"的预告，虽然后来被证明是过度预防，但它成功地将AI安全问题推到了公众视线。它打破了AI研究者默认假设"更强大的AI都是好的"这一观点，开启了关于AI治理的更广泛讨论。

其次，GPT-2展示了规模的力量。虽然它的架构（Transformer）已经存在两年，但仅仅通过增加参数、使用更好的数据，就能产生明显的能力提升。这为Scaling Laws论文的后续发表提供了有力的证据。

第三，GPT-2的分阶段开源策略，成为了后来AI开源与安全平衡的一个模板。不是完全保密，也不是不加思考地开源，而是有节奏、有考虑的渐进式发布。

最后，GPT-2代表了NLP研究的一个转折点。从这一刻起，"预训练-微调"不再仅仅是一个有效的方法，而是成为了事实上的标准范式。虽然BERT在学术基准上表现更好，但GPT-2因其生成能力的多功能性，实际上打开了一扇新门。这扇门最终导向了ChatGPT和今天的大语言模型时代。

当我们今天谈论GPT-2时，我们不仅在讨论一个具体的模型，而是在讨论一个时代的分界点。在GPT-2之前，深度学习是一种强大的工具。在GPT-2之后，人们开始相信，也许AI正在逼近某种形式的通用智能。那种"恐慌"——无论是出于安全考虑还是出于对AI能力的惊讶——也许正是这个转变的真实写照。