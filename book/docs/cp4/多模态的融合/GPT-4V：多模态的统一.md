---
sidebar_position: 2
---



## OpenAI的缓慢而谨慎的步伐

2023年的春天，OpenAI面临了一个微妙的困境。三月份发布的GPT-4已经证明了自己是当时最强大的语言模型，但一个秘密被媒体和研究社区所知晓——这个模型其实可以看。OpenAI的内部演示中，GPT-4能够解释超现实的图像、从iPhone截图中读取文字、识别出插在iPhone上的Lightning连接线，甚至能够识别为什么一个特定的表情包很有趣。这些能力令人惊叹，远超当时任何已知的多模态模型。

但OpenAI做了一个罕见的决定——他们选择了不发布这些能力。在官方宣布中，他们只字未提图像输入功能。原因很快被披露：安全顾虑、隐私问题、潜在的滥用风险。在一个通常崇尚"快速行动，打破常规"的科技产业中，OpenAI选择了谨慎。这个决定反映了一个深刻的认识：当一个模型变得足够强大时，其能力本身就成为了一个需要深思熟虑的设计问题，而不仅仅是一个技术问题。

六个月过去了。在这段时间里，OpenAI进行了广泛的"红队"测试——邀请外部专家试图找到模型可能被滥用的方式。他们进行了用户研究，收集了实际使用数据。2023年9月25日，GPT-4V（GPT-4 Vision）终于正式发布，但附带了一份详尽的系统卡片（System Card），详细阐述了模型的能力、局限、已知的风险和已实施的缓解措施。

这种发布方式本身就很有象征意义。它标志着从"多模态能力是一个有趣的研究方向"向"多模态理解是构建通用AI系统的基石"的转变。GPT-4V不是一个独立的多模态研究项目，而是对GPT-4本身的一个根本扩展。它代表着一个新时代的开始：当基础模型变得足够通用和强大时，它们自然而然地开始理解多种信息形式，而不需要特殊的多模态架构设计。

## 从"后处理"到"原生融合"的架构演变

要理解GPT-4V的意义，需要回顾一下多模态模型的发展历程。在Flamingo之前，许多研究者采用了一种朴素的方法：取一个预训练的视觉编码器（通常基于CLIP），取一个预训练的语言模型，然后通过某种形式的适配层将它们连接起来。Flamingo则推进了这一思想，提出了精妙的Perceiver Resampler和门控交叉注意力机制。

但GPT-4V采取了一个不同的策略。与其把视觉和语言看作两个需要"巧妙地连接"的独立系统，GPT-4V的设计理念是原生的多模态——从头开始，模型就被设计为理解多种形式的信息。虽然OpenAI从未公开详细的架构细节（这反映了该公司的商业政策），但从公开信息和研究社区的推断可以大致理解其工作方式。

GPT-4V采用了一个统一的transformer骨干网络，这个网络被优化为既能处理语言又能处理视觉信息。视觉输入通过一个深层的视觉骨干进行编码（很可能是基于Vision Transformer的架构），生成的视觉特征与文本嵌入进行融合。关键的创新在于交叉注意力模块的使用，这使得视觉和语言信息能够在多个层级上相互作用，甚至可以对像素级的视觉线索进行处理。

这种架构选择有一个微妙的含义。与Flamingo采用的"冻结预训练组件+适配层"方法不同，GPT-4V采用的是一个整体的、端到端训练的系统。这意味着视觉理解和语言生成能力从一开始就被紧密织在一起，而不是通过后期的微调或适配层来实现。

从某种意义上说，这是向自然的回归。人类不会先"看"再"说"，而是同时进行视觉处理和言语处理。这个选择也反映了一个不断验证的观点：当模型足够大且在足够多样的数据上训练时，它会自然地学会如何以统一的方式处理多种模态，而无需显式的架构提示。

## 能力的惊人广度

GPT-4V发布后的几个月内，它展现出的能力范围令整个研究社区感到惊讶。它不仅能够回答"这是什么？"的问题，更能够理解复杂的视觉-语言关系，进行推理，甚至进行创意任务。

在OCR（光学字符识别）方面，GPT-4V表现出众。它能够读取从各种源头摄录的文本，包括手写笔记、打印文档、甚至复杂的科学论文中的公式。这个能力看似简单，但其内涵深远。传统的OCR系统需要针对特定的文本类型进行专门训练。而GPT-4V通过通用的视觉-语言预训练就自动获得了这个能力，这体现了大规模预训练的威力。

在图像理解方面，GPT-4V表现得像一个博学的观察者。它能够识别物体、理解场景、推断因果关系。比如，给它一张人在办公室会议的照片，它不仅能识别出这是一个会议场景，还能推断出这可能是一个商业会议、识别可能的讨论主题、甚至推断这些人的角色关系。这种高层次的推理能力来自于GPT-4强大的语言理解能力与视觉编码的融合。

最令人印象深刻的能力也许是"幽默理解"。给GPT-4V一个梗图，它能够解释为什么它很有趣。这需要视觉理解（识别图像中的对象和行为）、文化知识（理解上下文引用）以及语言理解（理解文本中的双关或讽刺）的复杂融合。这个能力虽然看似琐碎，但它其实体现了一个深刻的事实：视觉和语言真的在同一个认知层次上被处理。

在学术和科学应用中，GPT-4V表现出了令人惊讶的能力。它能够查看科学图表和图形，理解其含义，并对其进行评论。在某些情况下，它甚至能够评估关于科学发现的声明的有效性。这对科学研究社区有潜在的价值——虽然你不应该完全依赖它，但它可以作为一个补充工具来理解复杂的视觉数据。

医学影像是另一个被探索的领域，尽管OpenAI明确声明GPT-4V不适合进行医学诊断。这个限制是明智的。在测试中，GPT-4V有时会对医学影像给出不一致的答案，有时甚至会忽视医学影像的基本约定（比如放射学中的"患者面向你"的观点）。这个局限性提醒我们，即使是最强大的模型也有其边界。

## 视觉推理的新范式

GPT-4V带来的一个真正创新的特性是"视觉推理"能力。这不仅仅是理解图像中发生了什么，而是能够在多个图像之间进行比较、推理因果关系、甚至解决需要视觉推理的谜题。

一个具体的例子是它能够根据代码生成视觉化。给GPT-4V一个LaTeX数学公式或Python绘图代码，它不仅能理解这段代码表示什么，还能想象出结果图像的样子。反过来，给它一个图像，它能够生成相应的代码来再现这个图像。这个双向能力体现了一个深刻的理解：代码和它的视觉输出之间存在一个意义的对应关系，而GPT-4V已经学会了在这两个表示之间进行转换。

在空间推理中，GPT-4V表现得甚至更令人印象深刻。它能够理解物体在三维空间中的位置关系，甚至能够根据二维图像推理出三维结构。给它一张复杂的建筑物照片，它不仅能描述建筑物，还能推理出不同部分的空间关系和可能的隐藏部分。

也许最有趣的是GPT-4V进行"视觉指点提示"的能力。这是一个OpenAI在系统卡片中提到的功能：用户可以在图像上绘制标记、圆圈或其他注释，然后提示模型"描述这个被圈出的物体"。模型会将注意力集中在标记的区域上，从而进行更精确的分析。这个功能体现了一个重要的交互设计原则：允许用户用最自然的方式（直接指向感兴趣的区域）来与模型交互，而不是被迫用文本描述。

## 局限与风险

尽管GPT-4V的能力令人印象深刻，但OpenAI在其系统卡片中坦诚地阐述了重要的局限。这种坦诚本身就值得赞赏，因为它反映了一个成熟的态度：承认模型的不完美是发展更好模型的第一步。

首先是"幻觉"问题。GPT-4V有时会生成看起来合理但实际上是虚构的信息。比如，它可能会对一张图像进行描述时，添加实际上不存在的细节。更棘手的是，这种幻觉往往发生时带有一种令人信服的语气，使得用户很容易被迷惑。

第二是偏见问题。由于GPT-4V是在互联网数据上训练的，它继承了网络中存在的各种社会偏见。在某些情况下，当提示包含性别或种族线索时，模型会做出刻板化的假设。更令人不安的是，在没有安全防护的情况下（在测试中这种情况被模拟），模型有时会根据人的外表做出不公平或有偏见的建议。

第三是医学建议的问题。GPT-4V明确不适合进行医学诊断或提供医疗建议。它可能会给出看起来权威的医学建议，但这些建议可能是错误的。在某些情况下，它对同一个问题给出的答案甚至会在不同的查询中不一致。

第四是安全问题。研究人员发现，GPT-4V有时可以识别出某些有害物质，但这个能力是不可靠的。它有时无法识别真实的危险物质，而在其他时候它可能会被欺骗。OpenAI因此明确建议不要使用GPT-4V来评估危险物质或化学物质。

第五是隐私和身份识别问题。GPT-4V可以识别公众人物和地标，这虽然有助于某些应用，但也引发了严重的隐私顾虑。为了应对这一点，OpenAI实施了一些措施来拒绝识别特定个人的请求（除了在特定的受控场景中，比如帮助低视力用户）。

第六是"提示注入"攻击的脆弱性。想象一个场景：一张图像中包含隐藏的文本指令。即使用户的提示是"描述这张图片"，图像中隐藏的文本可能会改变模型的行为。这体现了一个更普遍的问题：当模型变得足够聪明来理解隐含的指令时，它也变得足够脆弱来被那些隐含的指令所欺骗。

## 安全缓解措施与伦理考量

面对这些风险，OpenAI实施了多层次的缓解措施。其中一些是技术性的，比如在生成器头部添加拒绝分类器，当模型被提示执行某些有害任务时拒绝；其他则是系统层面的，比如限制对某些类型内容的访问，或要求明确的用户确认。

但更有趣的是OpenAI公开提出的伦理问题。系统卡片中明确指出了一些尚未解决的问题：比如，模型应该被允许推理人在图像中的性别、种族或情绪吗？对于视障用户来说，是否应该有特殊的考虑？这些问题没有简单的答案，反映了多模态AI在进入现实世界时面临的深刻伦理挑战。

这种透明度和自我批评的态度在AI行业中相对罕见。许多公司倾向于强调他们产品的能力，而忽视局限。OpenAI在这里选择了不同的路线：首先建立信任，通过诚实地承认问题和风险。

## 对整个多模态领域的影响

GPT-4V的发布和它随之而来的广泛应用，立即改变了整个多模态AI领域的景观。首先，它为开源社区树立了一个新的基准。LLaVA、Qwen-VL、CogVLM等开源多模态模型随之而来，尽管性能往往不如GPT-4V，但它们使得多模态能力变成了一个相对民主化的工具。

其次，它加速了多模态研究的步伐。在GPT-4V发布之前，许多研究者还在争论视觉-语言融合的最佳方式。GPT-4V的成功表明，一个足够大的、统一的变压器架构，训练在足够多样化的数据上，可以自然地发展出强大的多模态能力。这给了其他研究者一个清晰的方向。

第三，它证实了一个关键的观点：当模型变得足够通用时，它的能力范围往往会超出预期。人们原本以为视觉理解和语言生成需要专门设计的架构和注意力机制。但GPT-4V展示了，一个优雅设计的统一系统，给予足够的规模和训练数据，会自动涌现出这些能力。

最后，它改变了人们对AI安全的理解。GPT-4V的系统卡片和随之而来的研究表明，多模态能力不仅增加了新的功能，也增加了新的风险。这推动了AI安全研究的进展，特别是在理解这些新兴能力的潜在滥用方式方面。

## 前路未知

GPT-4V代表了一个里程碑，但不是终点。它成功地证明了多模态理解可以在一个统一的、通用的架构中实现。但关于如何进一步改进、如何更好地缓解已知的风险、如何扩展到更多的模态（音频、视频、三维）的问题仍然开放。

在技术层面，未来的挑战包括如何处理更长的视频序列、如何进行更精确的空间推理、如何减少幻觉。在社会层面，挑战包括如何使用这些能力的同时尊重隐私、如何防止滥用、如何确保公平和包容。

但无论这些挑战有多复杂，GPT-4V已经证明了多模态理解是构建通用AI系统的一个自然和必要的步骤。从这个意义上说，GPT-4V不仅是一个模型，更是一个清晰的信号：AI的未来将是多模态的。就像人类的理解能力来自于视觉、听觉、触觉等多种感觉的融合，AGI的道路也必然经过多模态理解这个关键节点。GPT-4V已经踏上了这条路，而它背后的洞察——统一的架构、大规模的预训练、多模态的融合——这些将持续指导AI研究向前。