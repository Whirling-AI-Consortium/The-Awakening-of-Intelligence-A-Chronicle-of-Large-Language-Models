---
sidebar_position: 4
---


没有任何争议比版权诉讼与生成内容归属问题更能揭示传统法律体系与新兴技术之间的根本冲突。

当《纽约时报》在2023年12月对OpenAI提起诉讼时，不仅仅是一场商业争端，更像是一个历史性的分水岭——人类创作者与机器智能之间关于知识产权的世纪之战正式拉开帷幕。截至2025年，已有44起与AI相关的版权诉讼在美国法院系统中展开，这些案件的判决结果也许将重新定义创造、所有权和公平使用的边界。

## 数字时代的潘多拉魔盒

现代大语言模型的训练需要海量的文本数据，而互联网上的大部分高质量内容都受到版权保护。当OpenAI的研究人员使用网络爬虫收集数据来训练GPT系列模型时，他们实际上是在创建人类历史上最大规模的"未经授权复制"行为。从《哈利波特》小说到《纽约时报》的新闻报道，从学术论文到博客文章，几乎所有的文字内容都被吸收进这些AI系统的"记忆"中。

这种做法的合法性依赖于一个古老但充满争议的法律概念——公平使用原则。该原则允许在特定情况下未经版权所有者许可使用受版权保护的材料，特别是当这种使用具有"变革性"性质时。然而，当我们面对的是能够生成数百万篇文章、数千首诗歌和无数代码片段的AI系统时，传统的公平使用框架是否仍然适用，成为了一个前所未有的法律难题。

这场版权战争的导火索可以追溯到2023年初。当时，一群视觉艺术家在Andersen v. Stability AI案中率先发起攻击，指控Stability AI、Midjourney和DeviantArt在未经许可的情况下，使用包括原告版权作品在内的数十亿张图像来训练其AI图像生成平台。艺术家们声称，这些公司从互联网上"抓取"了他们的作品，用于训练Stable Diffusion、Midjourney产品、DreamStudio和DreamUp等AI系统，既没有获得许可，也没有提供补偿。

随后，作家们加入了这场战斗。在Tremblay v. OpenAI案中，一群图书作者指控OpenAI从非法在线"影子图书馆"复制了他们的书籍，并用这些内容训练ChatGPT。著名喜剧演员Sarah Silverman也参与其中，与其他作者一起对OpenAI和Meta提起版权侵权诉讼，声称盗版版本的作品被未经许可地用于训练AI语言模型。

然而，真正将这场争议推向高潮的是《纽约时报》的诉讼。作为第一家对AI公司提起诉讼的主要媒体机构，《纽约时报》在其起诉书中详细描述了一种新型的"寄生"商业模式：AI公司通过复制和使用新闻机构的内容来训练其模型，然后这些模型生成的内容直接与原始新闻机构竞争，绕过了付费墙，破坏了传统媒体的商业模式。

在法庭上，AI公司和版权所有者之间的争论围绕着几个核心问题展开。首先是公平使用的定义和适用范围。AI公司普遍辩称，他们的系统对受版权保护材料的使用构成公平使用，因为这种使用是"变革性的"——AI模型不是简单地复制内容，而是"学习"其中的模式和结构，以生成全新的、原创的内容。

OpenAI在其回应中强调："使用公开可用的互联网材料训练AI模型是公平使用，这得到了长期和广泛接受的先例支持。"该公司引用了图书馆版权联盟的立场，即"基于既定先例，摄取受版权保护的作品来创建大语言模型或其他AI训练数据库通常是公平使用。"

然而，版权所有者们对此提出了强烈质疑。他们认为，AI训练涉及大规模的、商业性的复制行为，这种复制的规模和目的都超出了传统公平使用的范围。更重要的是，AI生成的内容直接与原始作品竞争，损害了版权所有者的潜在市场和作品价值。

## 首个重大判决的震撼效应

2025年2月11日，特拉华州联邦法院在Thomson Reuters v. Ross Intelligence案中做出了AI版权诉讼领域的首个重大判决。法官Stephanos Bibas明确裁定，使用受版权保护的材料训练AI系统不构成公平使用，这一判决为版权所有者赢得了重要胜利。

在这个案件中，法律研究巨头Thomson Reuters起诉其竞争对手Ross Intelligence，指控后者未经授权使用Westlaw的法律摘要来训练其AI搜索引擎。法官在详细分析了公平使用的四个要素后得出结论：Ross的使用是商业性的且不具变革性，因为它使用Thomson Reuters的受版权保护摘要作为AI训练数据来创建竞争性的法律研究产品。

更为重要的是，法官强调了公平使用分析中的第四个要素——对原作品市场的影响。他认识到，存在一个"明显的"使用受版权保护材料进行AI训练的潜在市场，越来越多的版权所有者正在与AI公司达成许可协议。这一认定可能对所有AI诉讼产生重大影响，因为它确认了AI训练存在既定的和不断增长的市场。

然而，就在几个月后，加利福尼亚州联邦法官William Alsup在涉及Anthropic的案件中做出了完全相反的裁决。在Andrea Bartz等三位作者对Anthropic提起的诉讼中，Alsup法官裁定，Anthropic使用书籍训练其Claude AI模型的行为构成公平使用，因为这种使用是"极其变革性的"。

法官在判决中写道："用于训练特定LLM的副本被认定为公平使用。除了受版权保护作品的性质之外，每个要素都支持这一结果。所涉及的技术是我们许多人一生中将看到的最具变革性的技术之一。"

这一判决的特殊之处在于，Alsup法官虽然支持AI公司在训练方面的公平使用辩护，但同时裁定Anthropic从互联网下载盗版书籍的行为仍然构成版权侵权。他明确指出："Anthropic后来购买了它早先从互联网上偷取的书籍副本，这不会免除它对盗窃行为的责任，但可能会影响法定损害赔偿的程度。"

除了训练数据的版权争议外，AI生成内容本身的版权归属问题同样复杂。根据美国版权法的现行规定，只有人类创作的作品才能获得版权保护。这一原则在著名的"猴子自拍"案（Naruto v. Slater）中得到确认，法院裁定猴子不能拥有它自己拍摄照片的版权。

2022年，艺术家Kristina Kashtanova使用Midjourney生成AI创作的图形小说《Zarya of the Dawn》的版权注册案例，生动地展示了这一困境。美国版权局最初批准了注册，但在得知Midjourney的作用后，开始了撤销程序。最终，版权局得出结论：Kashtanova是图形小说文本的作者，图像和文本的选择和安排也可以作为创意汇编受到保护，但单个图像被认为缺乏足够的人类创造性，因此新的注册证书明确排除了"人工智能生成的艺术品"。

这种处理方式反映了一个关键问题：究竟需要多少人类创造性投入才能使AI辅助创作的作品获得版权保护？这个问题的答案不仅影响着内容创作者的权益，也关系着整个AI产业的商业模式。

## 版权局的政策指导

2025年5月，美国版权局发布了一份108页的重要报告，专门探讨未经授权使用受版权保护材料训练生成AI系统是否可以辩护为公平使用。这份报告虽然不具有法律约束力，但代表了版权局的官方立场。

报告认为，生成AI系统的开发和部署涉及《版权法》赋予版权所有者的多项专有权利，包括创建副本和衍生作品的权利。报告特别指出，版权法的专有权利基于这样一个事实：人类对他们所经历的作品只保留"不完美的印象，通过他们自己独特的观点过滤"，而AI允许"创建完美的副本，并能够几乎瞬间分析作品"。

这表明，在版权局看来，如果作品可以在未经许可的情况下用作训练数据，《版权法》在鼓励创造力和鼓励创新之间的固有平衡可能无法在生成AI环境中按预期运作。

这场版权争议并非仅限于美国。在全球范围内，不同国家对AI生成内容的版权处理方式存在显著差异。英国的《版权、设计和专利法》允许对"计算机生成作品"给予版权保护，作者是"为创作作品进行必要安排的人"，保护期为创作后50年（而非人类作者死后70年）。

欧盟的情况更为复杂，因为其版权法是由13项指令和两项法规组成的拼接体。虽然这些立法都没有直接涉及AI生成作品的所有权问题，但欧洲法院在Infopaq案中提供了一些方向性指导，认为只有当原创性来自"作者自己的智力创造"时，版权才会存在。

中国在这方面表现出了相对进步的立场。2023年11月，北京互联网法院的一项里程碑式裁决承认了AI生成图像的版权保护，前提是作品展现原创性并反映人类的智力努力。这一决定表明中国对承认AI辅助创作在中国版权法下的进步立场。

版权诉讼的深层影响远超法律层面，它正在迫使整个AI产业重新思考其商业模式。如果法院最终裁定AI训练需要获得版权所有者的许可，那么AI公司可能需要与出版商、艺术家和其他内容所有者签署许可协议，这将显著影响AI公司的商业模式。

一些公司已经开始主动应对这一挑战。Shutterstock作为OpenAI的DALL-E训练"关键"的股票图像网站，已经开始向内容创作者支付费用，如果他们的作品被用于开发生成AI模型。生成AI初创公司Bria专门在其所谓的"负责任来源"数据集上训练其模型，当艺术家和股票图像提供商的创作被用于生成图像时，向他们支付版税。

与此同时，一些媒体公司选择了合作而非对抗的策略。《华盛顿邮报》与OpenAI达成协议，允许ChatGPT显示、总结和引用该报的内容。这种许可模式可能代表着未来的发展方向，但也引发了关于内容价值和议价能力的新问题。

面对AI训练的版权挑战，技术社区也在开发各种对策。芝加哥大学的Ben Zhao教授及其团队设计了一款名为Glaze的新工具。如果艺术家想要在网上发布作品而不面临图像生成器复制其风格的威胁，他们可以先将作品上传到Glaze，选择与自己不同的艺术风格。软件然后在像素级别对艺术家的作品进行数学更改，使其对计算机看起来不同，从而使其作为有效的训练数据变得无用。

这类技术的出现反映了创作者社区对未经授权使用其作品的深度担忧。正如Zhao教授所观察到的："大多数独立艺术家通过委托作品谋生，但他们发布作品的网站正在被AI模型抓取，以学习然后模仿特定风格。艺术家实际上正在被基于他们自己作品训练的模型所取代。"

面对这些复杂的法律和技术挑战，立法者们开始制定应对AI和版权问题的新法律。2024年4月9日，美国国会提出了《2024年生成AI版权披露法》，该法案要求开发生成AI模型的公司披露用于训练其系统的数据集，增加透明度，并可能让版权所有者对其作品有更多控制权。

另一项立法努力是2024年提出的《无AI欺诈法》，旨在防止AI在未经同意的情况下被用于冒充个人。这些立法尝试反映了政策制定者对平衡AI创新与创作者权利保护的努力。

Thomson Reuters案和Anthropic案判决的分化反映了AI版权法律的复杂性和不确定性。这种分化可能源于案件事实的差异：Thomson Reuters案涉及直接竞争对手使用专有数据创建竞争产品，而Anthropic案涉及更广泛的、更具变革性的生成AI应用。

然而，这种分化也揭示了更深层的问题：传统的公平使用框架是否足以应对AI时代的挑战？当AI系统能够处理和"学习"人类历史上几乎所有的文字和图像内容时，我们需要什么样的新法律框架来平衡创新与保护？

## 结语：未来的不确定性与可能性

传统的版权法律体系正面临着前所未有的挑战。AI技术的进步速度远超法律发展的节奏，而法院判决的分化表明，我们距离找到令各方满意的解决方案还有很长的路要走。

这场争议的最终结果将重新定义创造、所有权和公平的含义。如果版权所有者获胜，AI公司可能需要为训练数据支付巨额许可费，这可能会减缓AI发展的速度，但也会为内容创作者提供更好的保护。如果AI公司的公平使用辩护获得支持，那么AI技术可能会继续快速发展，但代价是传统内容创作者的利益可能受到损害。

更可能的情况是，我们将看到一个更加细致入微的解决方案：某些类型的AI训练可能被认定为公平使用，而其他类型则需要获得许可。同时，新的商业模式和技术解决方案可能会出现，试图在创新与保护之间找到平衡。

无论最终结果如何，这场版权诉讼与生成内容归属的争议已经永远改变了我们对知识产权的理解。在AI时代，创造不再是人类独有的特权，而法律体系必须适应这一新现实。这不仅是一场关于版权的争议，更是一场关于在智能机器时代如何定义人类价值和创造性的根本性辩论。