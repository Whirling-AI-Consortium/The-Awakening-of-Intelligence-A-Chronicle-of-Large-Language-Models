<!doctype html>
<html lang="zh-Hans" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-cp3/廉价的智慧" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">廉价的智慧 | 智能的觉醒</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://whirling-ai-consortium.github.io/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://whirling-ai-consortium.github.io/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://whirling-ai-consortium.github.io/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/docs/cp3/廉价的智慧"><meta data-rh="true" property="og:locale" content="zh_Hans"><meta data-rh="true" name="docusaurus_locale" content="zh-Hans"><meta data-rh="true" name="docsearch:language" content="zh-Hans"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="廉价的智慧 | 智能的觉醒"><meta data-rh="true" name="description" content="简化的力量"><meta data-rh="true" property="og:description" content="简化的力量"><link data-rh="true" rel="icon" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://whirling-ai-consortium.github.io/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/docs/cp3/廉价的智慧"><link data-rh="true" rel="alternate" href="https://whirling-ai-consortium.github.io/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/docs/cp3/廉价的智慧" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://whirling-ai-consortium.github.io/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/docs/cp3/廉价的智慧" hreflang="x-default"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/assets/css/styles.cd147f59.css">
<script src="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/assets/js/runtime~main.23d89510.js" defer="defer"></script>
<script src="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/assets/js/main.333741a6.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/img/logo.svg"><div role="region" aria-label="跳到主要内容"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">跳到主要内容</a></div><nav aria-label="主导航" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="切换导航栏" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/"><div class="navbar__logo"><img src="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/img/logo.svg" alt="My Book Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/img/logo.svg" alt="My Book Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">主页</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/docs/本书导览">Read Book</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/whirling-ai-consortium/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="切换浅色/暗黑模式（当前为浅色模式）" aria-label="切换浅色/暗黑模式（当前为浅色模式）" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="回到顶部" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="文档侧边栏" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/docs/本书导览">本书导览</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/docs/intro">前言</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/docs/category/第一章智能的拂晓">第一章：智能的拂晓</a><button aria-label="展开侧边栏分类 &#x27;第一章：智能的拂晓&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/docs/category/第二章ai江湖-人物与格局">第二章：AI江湖-人物与格局</a><button aria-label="展开侧边栏分类 &#x27;第二章：AI江湖-人物与格局&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/docs/category/第四章从llm到agi">第四章：从llm到agi</a><button aria-label="展开侧边栏分类 &#x27;第四章：从llm到agi&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/docs/category/第三章大语言模型技术发展历史">第三章：大语言模型技术发展历史</a><button aria-label="折叠侧边栏分类 &#x27;第三章：大语言模型技术发展历史&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/docs/cp3/前言">前言</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/docs/cp3/从词语开始">从词语开始</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/docs/cp3/预测的艺术">预测的艺术</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/docs/cp3/廉价的智慧">廉价的智慧</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/docs/cp3/序列的记忆">序列的记忆</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/docs/cp3/Attention Is All You Need">Attention Is All You Need</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/docs/cp3/聚焦的艺术">聚焦的艺术</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/docs/cp3/从无到有">从无到有</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/docs/结语：智能的新纪元">结语：智能的新纪元</a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="页面路径"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="主页面" class="breadcrumbs__link" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/docs/category/第三章大语言模型技术发展历史"><span itemprop="name">第三章：大语言模型技术发展历史</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">廉价的智慧</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">本页总览</button></div><div class="theme-doc-markdown markdown"><header><h1>廉价的智慧</h1></header><h3 class="anchor anchorWithStickyNavbar_LWe7" id="简化的力量">简化的力量<a href="#简化的力量" class="hash-link" aria-label="简化的力量的直接链接" title="简化的力量的直接链接">​</a></h3>
<p>AlexNet的胜利激励了NLP研究者们，但它也留下了一个尴尬的问题：深度学习在图像识别上表现如此出色，为什么应用到语言处理上还这么困难？</p>
<p>答案就隐藏在计算的复杂性中。</p>
<p>让我们回到Bengio的模型。虽然这个模型在概念上优雅，但在工程上却是一场噩梦。模型需要处理一个巨大的矩阵乘法：将隐藏层的输出（维度为H，通常在2000左右）与整个词汇表大小（V，百万级别）相乘，以计算每个单词的概率。这个V×H的计算主导了整个复杂度分析。更糟糕的是，计算完这些原始概率后，你还必须进行softmax归一化——对所有百万个单词计算指数和。这等于要计算V次指数运算。</p>
<p>用数字说话：如果你的隐藏层大小H是500，词汇表大小V是100万，那么每处理一个单词就需要进行5亿次浮点运算，再乘以你要处理的总单词数和训练轮数。即使用最快的CPU，这也意味着训练一个中等规模的模型需要数周甚至数月。这不仅是缓慢的问题，更是根本上不可行的问题。</p>
<p>2012年，AlexNet的成功吸引了人们对深度学习的关注，但当NLP研究者们试图重现这个成功时，他们很快发现：我们没有时间等待这么慢的训练。</p>
<p>正在这个时候，一个叫Tomas Mikolov的研究者有了一个激进的想法：<strong>为什么我们需要一个完整的神经网络语言模型呢？</strong> 为什么不能只是学习好的词向量？</p>
<p>2013年，Mikolov团队发表了两篇非常相关的论文，题目分别是《向量空间中词表征的有效估计》和《词与短语的分布式表征及其组合性》。这两篇论文一起引入了现在最著名的词向量工具——<strong>Word2Vec</strong>。</p>
<p>Mikolov做了什么？他采取了一系列看似激进的简化，最终创造了一个既简单又高效的模型。</p>
<p>首先，他抛弃了Bengio模型中昂贵的非线性隐藏层。记得那个用tanh激活函数的隐藏层吗？消除它。只保留线性运算。结果是一个所谓的&quot;对数线性模型&quot;（Log-linear Model）——输出概率的对数与输入是简单的线性关系。</p>
<p>其次，他采用了两种技巧来解决softmax的计算瓶颈。一种是<strong>分层softmax</strong>（Hierarchical Softmax），这是前人开发的技巧，它用一棵二叉树来组织词汇表，使得计算概率的复杂度从O(V)降低到O(log₂V)。当V是100万时，log₂V只有大约20。这是一个从数百万到二十的跳跃。第二种是<strong>负采样</strong>（Negative Sampling），这是一个更巧妙的技巧：与其计算所有单词的概率，不如只抽取几个&quot;负样本&quot;（不应该出现的单词）和一个正样本（应该出现的单词），训练模型去区分它们。理论证明这种做法虽然只使用K个样本（K通常是2到20之间），但仍然能收敛到正确的概率分布。</p>
<p>这两个简化一起，使得计算复杂度从数百万级别降低到了可以在几个小时内训练完成的程度。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="两个孪生模型">两个孪生模型<a href="#两个孪生模型" class="hash-link" aria-label="两个孪生模型的直接链接" title="两个孪生模型的直接链接">​</a></h3>
<p>Mikolov提出的模型有两种变体。第一种叫<strong>连续词袋模型</strong>（CBOW，Continuous Bag-of-Words），它用周围的词来预测中心词。第二种叫<strong>Skip-gram模型</strong>，反过来用中心词预测周围的词。</p>
<p>让我们聚焦于Skip-gram，因为这个模型在后来的应用中更为广泛。Skip-gram的想法非常简洁：给定一个词，预测它周围的词。</p>
<p>形式上，假设我们有一个句子w₁<!-- -->:T<!-- -->，我们要最大化对数似然：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mi>T</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></msubsup><msub><mo>∑</mo><mrow><mo>−</mo><mi>C</mi><mo>≤</mo><mi>j</mi><mo>≤</mo><mi>C</mi><mo separator="true">,</mo><mi>j</mi><mo mathvariant="normal">≠</mo><mn>0</mn></mrow></msub><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mi>j</mi></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>w</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\frac{1}{T}\sum_{t=1}^{T} \sum_{-C \le j \le C, j \ne 0} \log p(w_{t+j} | w_t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.417em;vertical-align:-0.4358em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1864em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.07153em">C</span><span class="mrel mtight">≤</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span><span class="mrel mtight">≤</span><span class="mord mathnormal mtight" style="margin-right:0.07153em">C</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span><span class="mrel mtight"><span class="mrel mtight"><span class="mord vbox mtight"><span class="thinbox mtight"><span class="rlap mtight"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="inner"><span class="mord mtight"><span class="mrel mtight"></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel mtight">=</span></span><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<p>这里C定义了&quot;周围&quot;的范围。如果C=2，那么我们在预测一个词时，只考虑它左边和右边各两个词。</p>
<p>关键的创新在于如何计算条件概率<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mi>j</mi></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>w</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(w_{t+j}|w_t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。Mikolov用一个简单的点积：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mi>j</mi></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>w</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mo stretchy="false">⟨</mo><msub><mi>u</mi><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mi>j</mi></mrow></msub></msub><mo separator="true">,</mo><msub><mi>c</mi><msub><mi>w</mi><mi>t</mi></msub></msub><mo stretchy="false">⟩</mo><mo stretchy="false">)</mo></mrow><mrow><msub><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>V</mi></mrow></msub><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mo stretchy="false">⟨</mo><msub><mi>u</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>c</mi><msub><mi>w</mi><mi>t</mi></msub></msub><mo stretchy="false">⟩</mo><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">p(w_{t+j} | w_t) = \frac{\exp(\langle u_{w_{t+j}}, c_{w_t} \rangle)}{\sum_{i \in V} \exp(\langle u_i, c_{w_t} \rangle)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.7792em;vertical-align:-0.5896em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1897em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1667em"><span style="top:-2.1786em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:0.22222em">V</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3494em"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.1952em"></span><span class="mop mtight"><span class="mtight">e</span><span class="mtight">x</span><span class="mtight">p</span></span><span class="mopen mtight">(⟨</span><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:-0.0269em;margin-right:0.1em"><span class="pstrut" style="height:2.6151em"></span><span class="mord mathnormal mtight">t</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2703em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span></span></span></span></span></span></span><span class="mclose mtight">⟩)</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.6647em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mtight">e</span><span class="mtight">x</span><span class="mtight">p</span></span><span class="mopen mtight">(⟨</span><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:-0.0269em;margin-right:0.1em"><span class="pstrut" style="height:2.6595em"></span><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5092em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5067em"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:-0.0269em;margin-right:0.1em"><span class="pstrut" style="height:2.6151em"></span><span class="mord mathnormal mtight">t</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2703em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span></span></span></span></span></span></span><span class="mclose mtight">⟩)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5896em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p>这里c和u分别是&quot;输入词向量&quot;和&quot;输出词向量&quot;。这些向量就是模型要学习的参数。注意这里没有任何非线性变换，没有隐藏层，只是词向量之间的点积。</p>
<p>这听起来太简单了。但正是这种简单性，使得模型可以在巨大的数据集上快速训练。而且，令人惊讶的是，这个简单的模型学到的词向量具有非常有趣的性质。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="向量中的奥秘">向量中的奥秘<a href="#向量中的奥秘" class="hash-link" aria-label="向量中的奥秘的直接链接" title="向量中的奥秘的直接链接">​</a></h3>
<p>当Mikolov的团队用Skip-gram模型在数十亿单词的语料上训练后，发生了一件奇妙的事：词向量中出现了<strong>语言规律</strong>。</p>
<p>这听起来可能有点抽象，但具体例子会让它变得非常清晰。比如，模型学到的&quot;king&quot;（国王）、&quot;queen&quot;（皇后）、&quot;man&quot;（男人）、&quot;woman&quot;（女人）的词向量之间有一个令人惊讶的关系：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mtext>king</mtext><mo>⃗</mo></mover><mo>−</mo><mover accent="true"><mtext>man</mtext><mo>⃗</mo></mover><mo>+</mo><mover accent="true"><mtext>woman</mtext><mo>⃗</mo></mover><mo>≈</mo><mover accent="true"><mtext>queen</mtext><mo>⃗</mo></mover></mrow><annotation encoding="application/x-tex">\vec{\text{king}} - \vec{\text{man}} + \vec{\text{woman}} \approx \vec{\text{queen}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1719em;vertical-align:-0.1944em"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9774em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord text"><span class="mord">king</span></span></span><span style="top:-3.2634em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.2355em"><span class="overlay" style="height:0.714em;width:0.471em"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7973em;vertical-align:-0.0833em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord text"><span class="mord">man</span></span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.2355em"><span class="overlay" style="height:0.714em;width:0.471em"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.714em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord text"><span class="mord">woman</span></span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.2355em"><span class="overlay" style="height:0.714em;width:0.471em"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.9084em;vertical-align:-0.1944em"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord text"><span class="mord">queen</span></span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.2355em"><span class="overlay" style="height:0.714em;width:0.471em"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em"><span></span></span></span></span></span></span></span></span></p>
<p>换句话说，如果你取&quot;国王&quot;的向量，减去&quot;男人&quot;的向量，再加上&quot;女人&quot;的向量，你会得到一个与&quot;皇后&quot;向量非常接近的新向量。</p>
<p>或者另一个例子：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mtext>Russia</mtext><mo>⃗</mo></mover><mo>+</mo><mover accent="true"><mtext>river</mtext><mo>⃗</mo></mover><mo>≈</mo><mover accent="true"><mtext>Volga River</mtext><mo>⃗</mo></mover></mrow><annotation encoding="application/x-tex">\vec{\text{Russia}} + \vec{\text{river}} \approx \vec{\text{Volga River}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0497em;vertical-align:-0.0833em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9663em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord text"><span class="mord">Russia</span></span></span><span style="top:-3.2523em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.2355em"><span class="overlay" style="height:0.714em;width:0.471em"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.9509em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9509em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord text"><span class="mord">river</span></span></span><span style="top:-3.2369em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.2355em"><span class="overlay" style="height:0.714em;width:0.471em"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.1719em;vertical-align:-0.1944em"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9774em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord text"><span class="mord">Volga River</span></span></span><span style="top:-3.2634em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.2355em"><span class="overlay" style="height:0.714em;width:0.471em"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em"><span></span></span></span></span></span></span></span></span></p>
<p>&quot;俄罗斯&quot;加上&quot;河流&quot;大约等于&quot;伏尔加河&quot;。</p>
<p>让我停下来强调一下，这有多么不同寻常。Mikolov的模型是在一个简单的、无关的任务上训练的——只是预测相邻的词。模型没有被明确地告知&quot;king&quot;和&quot;queen&quot;之间的语义关系，也没有被教导什么是&quot;首都&quot;或&quot;河流&quot;。它纯粹通过在大量文本上进行统计学习，自动发现了这些关系。</p>
<p>从数学的角度，这意味着词向量空间的结构捕捉了自然语言中的某些基本规律。相似的词在这个空间中聚集在一起，而语义关系对应于向量的偏移。如果&quot;国王&quot;和&quot;皇后&quot;之间的关系是某个方向和距离，那么&quot;男人&quot;和&quot;女人&quot;之间的关系大约是同一个方向和距离。</p>
<p>这个发现激发了人们的想象。如果一个为了预测相邻词而训练的简单线性模型能学到这样的结构，那么更复杂的模型会学到什么？如果我们在更大的数据集上训练，会发生什么？如果我们用这些预训练的词向量作为其他NLP任务的初始化，会发生什么？</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="为什么这有效">为什么这有效？<a href="#为什么这有效" class="hash-link" aria-label="为什么这有效？的直接链接" title="为什么这有效？的直接链接">​</a></h3>
<p>但这里有一个哲学问题：为什么一个简单的线性模型，通过在&quot;预测下一个词&quot;这个看似简单的任务上进行训练，能学到如此丰富的语义结构？</p>
<p>答案涉及一个深刻的观察，我们在Bengio的论文中已经看到过。如果词向量被很好地组织，使得语义上相似的词拥有相似的向量，那么预测任务会变得容易。为什么？因为如果&quot;cat&quot;（猫）和&quot;dog&quot;（狗）在向量空间中靠近，那么句子&quot;The cat is sleeping&quot;和&quot;The dog is sleeping&quot;中的&quot;cat&quot;和&quot;dog&quot;位置互换时，模型应该给出相似的概率。</p>
<p>但这还不足以解释语义关系的线性结构。更深层的原因与<strong>组合性</strong>（Compositionality）有关——自然语言中的复杂含义是通过简单含义的组合而成的。&quot;King&quot;这个词的含义可以分解为某些基本属性的组合，比如&quot;权力&quot;、&quot;男性&quot;等等。如果模型通过学习预测邻近词来隐含地建模这些属性，那么它自然会在向量空间中形成一个能够表达这些属性的结构。</p>
<p>在Mikolov的第三篇相关论文《连续空间中的语言规律》中，作者们直接研究了这个现象，发现许多语义和句法关系都对应于向量空间中的近似恒定偏移。这不是一个理论预测，而是一个实证发现——他们在大规模词向量上系统地验证了这一点。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="一场静悄悄的革命">一场静悄悄的革命<a href="#一场静悄悄的革命" class="hash-link" aria-label="一场静悄悄的革命的直接链接" title="一场静悄悄的革命的直接链接">​</a></h3>
<p>但这里有个容易被忽视的细节：Word2Vec的模型本身<strong>不是完整的语言模型</strong>。回忆我们之前的定义，语言模型应该能够计算任意单词序列的概率p(w₁<!-- -->:T<!-- -->)。但Word2Vec做的是邻近词预测，这完全不同。</p>
<p>这是有意为之的。Mikolov在论文中明确指出，他们的目标不是构建完整的语言模型，而是<strong>学习好的词向量作为特征</strong>，这些特征可以被用于其他任务。他们承认Bengio在2003年就有了学习词向量的想法，但Bengio的方法非常昂贵，因为他试图同时学习完整的语言模型。Mikolov的洞察是：也许我们可以分离这两个目标。先用一个廉价的、简单的方法学习词向量，然后用这些向量作为其他模型（比如完整的语言模型或分类模型）的输入。</p>
<p>这个想法改变了一切。突然间，学习有用的词向量变成了一个可以在几小时而不是几周内完成的任务。而且这些词向量可以被免费提供给整个社区使用。研究者们可以下载预训练的Word2Vec词向量，用于他们自己的NLP系统，获得显著的性能提升。</p>
<p>从这一刻起，词向量成为了NLP的基础设施。这不仅仅是因为Word2Vec本身的聪明设计，也是因为它在时间和空间上的可访问性。在AlexNet的鼓舞下，随着GPU计算的普及和深度学习工具的改进，NLP研究者们现在可以用廉价而高效的方式获得高质量的词表征。</p>
<p>当然，Word2Vec不是唯一的方法。2014年，Pennington等人发表了GloVe（Global Vectors for Word Representation），提供了一个统一的视角来理解全局矩阵分解方法和局部上下文窗口方法。之后还有Skip-thought vectors、Eigenwords等许多其他方法。但Word2Vec因其简洁、高效和有效性，成为了这个时代最标志性的成果。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="上下文的觉醒">上下文的觉醒<a href="#上下文的觉醒" class="hash-link" aria-label="上下文的觉醒的直接链接" title="上下文的觉醒的直接链接">​</a></h3>
<p>但是，Word2Vec有一个根本的局限性：它为每个词学习了一个固定的向量表示，而不考虑该词出现的上下文。这是一个问题，因为词的含义常常依赖于上下文——这个现象叫做<strong>多义性</strong>（Polysemy）。比如&quot;bank&quot;这个词，可以指金融机构也可以指河岸。一个固定的词向量必须在这两个含义之间进行某种妥协。</p>
<p>2016年前后，研究者们开始探索<strong>上下文相关的词向量</strong>。一种方法是使用双向LSTM（长短期记忆网络）的隐藏状态作为上下文相关的词表示。比如Context2vec或者后来的McCann等人的方法，都采用了这个思路。</p>
<p>但最著名的是2018年的ELMo（Embeddings from Language Models），由Peters等人提出。ELMo做了两件重要的事。第一，它使用双向LSTM来计算上下文相关的词表示。第二，它将这些表示与下游任务的微调相结合——先在大规模无标注数据上预训练，然后在具体的任务数据上进行有监督的微调。</p>
<p>这个想法虽然看似简单，但它预示了未来的发展方向。它表明，我们可以用无监督的预训练学习一般性的语言表示，然后通过有监督的微调适应特定任务。这个范式在几年后会被广泛采用，成为现代NLP的标准做法。</p>
<p>但在2018年，这还只是一个有前景的开始。真正的下一步——从词向量到整句甚至整个段落的更强大表示——需要一个不同的架构。这个架构已经在计算机视觉中被证明了，现在轮到NLP领域了。</p>
<p>它的名字叫Transformer。</p>
<p>但在我们到达那里之前，我们需要先理解循环神经网络为什么陷入了困境，以及为什么Transformer能够突破这个困境。</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/whirling-ai-consortium/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/edit/main/docs/cp3/廉价的智慧.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>编辑此页</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="文件选项卡"><a class="pagination-nav__link pagination-nav__link--prev" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/docs/cp3/预测的艺术"><div class="pagination-nav__sublabel">上一页</div><div class="pagination-nav__label">预测的艺术</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/docs/cp3/序列的记忆"><div class="pagination-nav__sublabel">下一页</div><div class="pagination-nav__label">序列的记忆</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#简化的力量" class="table-of-contents__link toc-highlight">简化的力量</a></li><li><a href="#两个孪生模型" class="table-of-contents__link toc-highlight">两个孪生模型</a></li><li><a href="#向量中的奥秘" class="table-of-contents__link toc-highlight">向量中的奥秘</a></li><li><a href="#为什么这有效" class="table-of-contents__link toc-highlight">为什么这有效？</a></li><li><a href="#一场静悄悄的革命" class="table-of-contents__link toc-highlight">一场静悄悄的革命</a></li><li><a href="#上下文的觉醒" class="table-of-contents__link toc-highlight">上下文的觉醒</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Read</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/docs/intro">Introduction</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/whirling-ai-consortium/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models/discussions" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub Discussions<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/whirling-ai-consortium/The-Awakening-of-Intelligence-A-Chronicle-of-Large-Language-Models" target="_blank" rel="noopener noreferrer" class="footer__link-item" remarkplugins="" rehypeplugins="">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Whirling AI Consortium. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>